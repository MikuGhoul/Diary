## virtio-blk front-end initialize
* virtio_blk的前端，即 gueset linux kernel中的代码
* Linux kernel 4.10左右, 我下面的函数详细分析中过滤掉了不太重要的代码

####　调用流程
``` c
virtblk_probe
	=> init_vq
		=> virtio_cread_feature # 查看是否配置了多队列
		=> find_vqs
			=> vp_find_vqs
				=> vp_try_to_find_vqs
					=> vp_request_intx/vp_request_msix_vectors # 给vq分配中断
						=> request_irq
					=> vp_setup_vq
						=> setup_vq # 这个setup_vq是在virtio_pci_legacy_probe/virtio_pci_modern_probe中挂上的指针函数
							=> iowrite16 # 选择queue
							=> ioread16 # 读取queue num
							=> vring_create_virtqueue
								=> vring_alloc_queue # 给queue申请物理page
									=> vring_size # 获取vring的size
									=> alloc_pages_exact # 申请page
									=> virt_to_phys # 获取queue的物理地址
								=> vring_init # 把上面的物理page分配给vring的desc，avail，used
								=> __vring_new_virtqueue
                            => iowrite32 # 把queue的gpa传给qemu
```


#### 详细分析
* virtblk_probe
    * 在virtio_blk这个driver被挂载后就会调用，详见kernel的bus、device、driver模型
    * 自动传入driver对应的device

``` c
static int virtblk_probe(struct virtio_device *vdev)
{
    // 分配vblk这个抽象结构, 和vdev关联
    vdev->priv = vblk = kmalloc(sizeof(*vblk), GFP_KERNEL);
    vblk->vdev = vdev;
    init_vq(vblk);
}
```

* init_vq
    * 用来初始化virtqueue
    * 先调用virtio_cread_feature来读device的config space, 判断开没开多队列(内核层的mq), 没开就只分配一个virtqueue
    * 然后就按num_vqs这个数量来分配virtqueue，name、callback等，注意这里callback是virtqueue_done，后面回调就这个函数了，搞笑的是这个virtblk_done callback作为参数会一直传递到__vring_new_virtqueue里面才真正的赋值给vq.callback
    * vqs(不是blk->vqs)，是分配virtqueue的实际载体，可以看到第二个循环里就是把vblk->vqs的指针指向vqs
    * 重点就是find_vqs了

``` c
static int init_vq(struct virtio_blk *vblk)
{
	err = virtio_cread_feature(vdev, VIRTIO_BLK_F_MQ,
				   struct virtio_blk_config, num_queues,
				   &num_vqs);
    if (err)
        num_vqs = 1;
	vblk->vqs = kmalloc(sizeof(*vblk->vqs) * num_vqs, GFP_KERNEL);
	names = kmalloc(sizeof(*names) * num_vqs, GFP_KERNEL);
	callbacks = kmalloc(sizeof(*callbacks) * num_vqs, GFP_KERNEL);

	vqs = kmalloc(sizeof(*vqs) * num_vqs, GFP_KERNEL);

	for (i = 0; i < num_vqs; i++) {
		callbacks[i] = virtblk_done;
		snprintf(vblk->vqs[i].name, VQ_NAME_LEN, "req.%d", i);
		names[i] = vblk->vqs[i].name;
	}

	err = vdev->config->find_vqs(vdev, num_vqs, vqs, callbacks, names);

	for (i = 0; i < num_vqs; i++) {
		spin_lock_init(&vblk->vqs[i].lock);
		vblk->vqs[i].vq = vqs[i];
	}
	vblk->num_vqs = num_vqs;

}
```

* vp_find_vqs
    * the config->find_vqs() implementation
    * legacy和modern这里有点小区别，但不大，都会调用到vp_find_vqs
    * 再根据中断的配置情况来调用vp_try_to_find_vqs，有三种情况，在vp_try_to_find_vqs里做判断
        * 使用msix中断，n + 1个vector，n个vq都有自己对应的vector，1个给change中断
        * 使用msix中断，2个vector，所有vq共享一个vector，1个给change中断
        * 使用intx中断，1个vector，所有vq和change共享1个中断
``` c
int vp_find_vqs(struct virtio_device *vdev, unsigned nvqs,
		struct virtqueue *vqs[],
		vq_callback_t *callbacks[],
		const char * const names[])
{
	int err;

	/* Try MSI-X with one vector per queue. */
	err = vp_try_to_find_vqs(vdev, nvqs, vqs, callbacks, names, true, true);
	if (!err)
		return 0;
	/* Fallback: MSI-X with one vector for config, one shared for queues. */
	err = vp_try_to_find_vqs(vdev, nvqs, vqs, callbacks, names,
				 true, false);
	if (!err)
		return 0;
	/* Finally fall back to regular interrupts. */
	return vp_try_to_find_vqs(vdev, nvqs, vqs, callbacks, names,
				  false, false);
}
```

* vp_try_to_find_vqs
    * 主要是两部分，先分配中断，然后调用vp_setup_vq
    * 中断
        * 上面说了有三种情况，在这里做判断，以best option为例，nvector表示中断数量（n + 1）
        * 调用vp_request_msix_vectors

``` c
static int vp_try_to_find_vqs(struct virtio_device *vdev, unsigned nvqs,
			      struct virtqueue *vqs[],
			      vq_callback_t *callbacks[],
			      const char * const names[],
			      bool use_msix,
			      bool per_vq_vectors)
{
	struct virtio_pci_device *vp_dev = to_vp_device(vdev);
	vp_dev->vqs = kmalloc(nvqs * sizeof *vp_dev->vqs, GFP_KERNEL);

	if (!use_msix) {
		/* Old style: one normal interrupt for change and all vqs. */
		err = vp_request_intx(vdev);
		if (err)
			goto error_find;
	} else {
		if (per_vq_vectors) {
			/* Best option: one for change interrupt, one per vq. */
			nvectors = 1;
			for (i = 0; i < nvqs; ++i)
				if (callbacks[i])
					++nvectors;
		} else {
			/* Second best: one for change, shared for all vqs. */
			nvectors = 2;
		}

		err = vp_request_msix_vectors(vdev, nvectors, per_vq_vectors);
		if (err)
			goto error_find;
	}

	vp_dev->per_vq_vectors = per_vq_vectors;
	allocated_vectors = vp_dev->msix_used_vectors;
	for (i = 0; i < nvqs; ++i) {
		if (!names[i]) {
			vqs[i] = NULL;
			continue;
		} else if (!callbacks[i] || !vp_dev->msix_enabled)
			msix_vec = VIRTIO_MSI_NO_VECTOR;
		else if (vp_dev->per_vq_vectors)
			msix_vec = allocated_vectors++;
		else
			msix_vec = VP_MSIX_VQ_VECTOR;
		vqs[i] = vp_setup_vq(vdev, i, callbacks[i], names[i], msix_vec);
		if (!vp_dev->per_vq_vectors || msix_vec == VIRTIO_MSI_NO_VECTOR)
			continue;

		/* allocate per-vq irq if available and necessary */
		snprintf(vp_dev->msix_names[msix_vec],
			 sizeof *vp_dev->msix_names,
			 "%s-%s",
			 dev_name(&vp_dev->vdev.dev), names[i]);
		err = request_irq(vp_dev->msix_entries[msix_vec].vector,
				  vring_interrupt, 0,
				  vp_dev->msix_names[msix_vec],
				  vqs[i]);
	}
}

```

* vp_request_msix_vectors
    * 请求中断的wrapper，真正的请求是request_irq，到这里就不深入了，是kernel中断处理的部分了，简单来说就是请求中断，注册了中断处理函数
    * 可以看到有vp_config_changed和vp_vring_interrupt两个中断handler
        * vp_config_changed是在device的config space改变的时候中断handler
        * vp_vring_interrupt是device向vq中写入信息的时候产生的中断的handler，这个很重要，是qemu处理完数据后打中断给gueset的处理函数，这个函数会调用vring_interrupt，然后调用vq.callback，也就是上面说传递了很多层的的virtblk_done函数
    * 这个vp_vring_interrupt是vq共享一个中断的时候才会注册的，每个vq一个中断vector的时候是在vp_setup_vq返回后，注册的vring_interrupt，其实可以看到vp_vring_interrupt也是会调用vring_interrupt，但加了锁

``` c
static int vp_request_msix_vectors(struct virtio_device *vdev, int nvectors,
				   bool per_vq_vectors)
{
	vp_dev->msix_vectors = nvectors;

	vp_dev->msix_entries = kmalloc(nvectors * sizeof *vp_dev->msix_entries,
				       GFP_KERNEL);
	vp_dev->msix_names = kmalloc(nvectors * sizeof *vp_dev->msix_names,
				     GFP_KERNEL);
	vp_dev->msix_affinity_masks
		= kzalloc(nvectors * sizeof *vp_dev->msix_affinity_masks,
			  GFP_KERNEL);

	for (i = 0; i < nvectors; ++i)
		vp_dev->msix_entries[i].entry = i;

	vp_dev->msix_enabled = 1;

	/* Set the vector used for configuration */
	v = vp_dev->msix_used_vectors;
	snprintf(vp_dev->msix_names[v], sizeof *vp_dev->msix_names,
		 "%s-config", name);
	err = request_irq(vp_dev->msix_entries[v].vector,
			  vp_config_changed, 0, vp_dev->msix_names[v],
			  vp_dev);

	++vp_dev->msix_used_vectors;

	v = vp_dev->config_vector(vp_dev, v);

	if (!per_vq_vectors) {
		/* Shared vector for all VQs */
		v = vp_dev->msix_used_vectors;
		snprintf(vp_dev->msix_names[v], sizeof *vp_dev->msix_names,
			 "%s-virtqueues", name);
		err = request_irq(vp_dev->msix_entries[v].vector,
				  vp_vring_interrupt, 0, vp_dev->msix_names[v],
				  vp_dev);
		if (err)
			goto error;
		++vp_dev->msix_used_vectors;
	}
}

```
* 回到vp_try_to_find_vqs中，接下来会调用vp_setup_vq

* vp_setup_vq
    * 主要是调用了vp_dev->setup_vq，这个函数指针是在virtio_pci_modern_probe/virtio_pci_legacy_probe中挂上去的，两种模式有不同的实现

``` c
static struct virtqueue *vp_setup_vq(struct virtio_device *vdev, unsigned index,
				     void (*callback)(struct virtqueue *vq),
				     const char *name,
				     u16 msix_vec)
{
	struct virtio_pci_device *vp_dev = to_vp_device(vdev);
	struct virtio_pci_vq_info *info = kmalloc(sizeof *info, GFP_KERNEL);
	struct virtqueue *vq;
	unsigned long flags;

	/* fill out our structure that represents an active queue */
	if (!info)
		return ERR_PTR(-ENOMEM);

	vq = vp_dev->setup_vq(vp_dev, info, index, callback, name, msix_vec);
	if (IS_ERR(vq))
		goto out_info;

	info->vq = vq;
	if (callback) {
		spin_lock_irqsave(&vp_dev->lock, flags);
		list_add(&info->node, &vp_dev->virtqueues);
		spin_unlock_irqrestore(&vp_dev->lock, flags);
	} else {
		INIT_LIST_HEAD(&info->node);
	}

	vp_dev->vqs[index] = info;
	return vq;

out_info:
	kfree(info);
	return vq;
}

```

* setup_vq
    * 主要有4步
        * 选择queue
        * 检查queue是否可用
        * 创建vring
        * 激活这个queue
    * 先看legacy中的setup_vq
        * iowrite16，向device的config space的IO映射地址写入我们需要的queue的index，这会导致vm exit，进入qemu里面，执行qemu中的逻辑，这里可以简答理解为一个黑盒，就是向这个地址打中断会导致device切换到这个queue
        * ioread16，和上面差不多，注意这里读出来的num不是vq的数量，而是descriptor table的表项数量
        * 调用vring_create_virtqueue
        * VIRTIO_PCI_QUEUE_SEL、VIRTIO_PCI_QUEUE_PFN、VIRTIO_MSI_QUEUE_VECTOR等等这些config space偏移地址在qemu里也有，搜一搜就看得到，在hw/virtio/virtio-pci.c中的virtio_ioport_write和virtio_ioport_read就是config space io映射读写进入到qemu中的逻辑

``` c
static struct virtqueue *setup_vq(struct virtio_pci_device *vp_dev,
				  struct virtio_pci_vq_info *info,
				  unsigned index,
				  void (*callback)(struct virtqueue *vq),
				  const char *name,
				  u16 msix_vec)
{
	struct virtqueue *vq;
	u16 num;
	int err;

	/* Select the queue we're interested in */
	iowrite16(index, vp_dev->ioaddr + VIRTIO_PCI_QUEUE_SEL);

	/* Check if queue is either not available or already active. */
	num = ioread16(vp_dev->ioaddr + VIRTIO_PCI_QUEUE_NUM);
	if (!num || ioread32(vp_dev->ioaddr + VIRTIO_PCI_QUEUE_PFN))
		return ERR_PTR(-ENOENT);

	info->msix_vector = msix_vec;

	/* create the vring */
	vq = vring_create_virtqueue(index, num,
				    VIRTIO_PCI_VRING_ALIGN, &vp_dev->vdev,
				    true, false, vp_notify, callback, name);
	if (!vq)
		return ERR_PTR(-ENOMEM);

	/* activate the queue */
	iowrite32(virtqueue_get_desc_addr(vq) >> VIRTIO_PCI_QUEUE_ADDR_SHIFT,
		  vp_dev->ioaddr + VIRTIO_PCI_QUEUE_PFN);

	vq->priv = (void __force *)vp_dev->ioaddr + VIRTIO_PCI_QUEUE_NOTIFY;

	if (msix_vec != VIRTIO_MSI_NO_VECTOR) {
		iowrite16(msix_vec, vp_dev->ioaddr + VIRTIO_MSI_QUEUE_VECTOR);
		msix_vec = ioread16(vp_dev->ioaddr + VIRTIO_MSI_QUEUE_VECTOR);
		if (msix_vec == VIRTIO_MSI_NO_VECTOR) {
			err = -EBUSY;
			goto out_deactivate;
		}
	}

	return vq;
}

```
* vring_create_virtqueue
    * 提醒一下，num是decriptor table的表项的数量，也就是buffer的个数，必须是2 ^ n
    * 先检测2 ^ n，然后通过vring_size计算出vring的size，然后通过调用vring_alloc_queue申请vring的内存，这里还考虑到了没内存的情况，num/2来减少buffer的数量重新申请，实在没办法就申请一个物理页
    * 然后调用vring_init来初始化vring结构体，就是把申请来的内存在结构体中记上

``` c
struct virtqueue *vring_create_virtqueue(
	unsigned int index,
	unsigned int num,
	unsigned int vring_align,
	struct virtio_device *vdev,
	bool weak_barriers,
	bool may_reduce_num,
	bool (*notify)(struct virtqueue *),
	void (*callback)(struct virtqueue *),
	const char *name)
{
	struct virtqueue *vq;
	void *queue = NULL;
	dma_addr_t dma_addr;
	size_t queue_size_in_bytes;
	struct vring vring;

	/* We assume num is a power of 2. */
	if (num & (num - 1)) {
		dev_warn(&vdev->dev, "Bad virtqueue length %u\n", num);
		return NULL;
	}

	/* TODO: allocate each queue chunk individually */
	for (; num && vring_size(num, vring_align) > PAGE_SIZE; num /= 2) {
		queue = vring_alloc_queue(vdev, vring_size(num, vring_align),
					  &dma_addr,
					  GFP_KERNEL|__GFP_NOWARN|__GFP_ZERO);
		if (queue)
			break;
	}

	if (!num)
		return NULL;

	if (!queue) {
		/* Try to get a single page. You are my only hope! */
		queue = vring_alloc_queue(vdev, vring_size(num, vring_align),
					  &dma_addr, GFP_KERNEL|__GFP_ZERO);
	}
	if (!queue)
		return NULL;

	queue_size_in_bytes = vring_size(num, vring_align);
	vring_init(&vring, num, queue, vring_align);

	vq = __vring_new_virtqueue(index, vring, vdev, weak_barriers,
				   notify, callback, name);
	if (!vq) {
		vring_free_queue(vdev, queue_size_in_bytes, queue,
				 dma_addr);
		return NULL;
	}

	to_vvq(vq)->queue_dma_addr = dma_addr;
	to_vvq(vq)->queue_size_in_bytes = queue_size_in_bytes;
	to_vvq(vq)->we_own_ring = true;

	return vq;
}
```

* vring_size
    * ving包括三部分，参见include/uapi/linux/virtio_ring.h中vring的定义
        * vring_desc包括了descriptor table，所以是sizeof(struct vring_desc) * num
        * vring_avail包括三个指针和一个avail ring数组，所以是sizeof(__virtio16) * (3 + num)
        * vring_used包括三个指针和一个used ring数组，这个数组的元素是vring_used_elem，所以是sizeof(__virtio16) * 3 + sizeof(struct vring_used_elem) * num
``` c
static inline unsigned vring_size(unsigned int num, unsigned long align)
{
	return ((sizeof(struct vring_desc) * num + sizeof(__virtio16) * (3 + num)
		 + align - 1) & ~(align - 1))
		+ sizeof(__virtio16) * 3 + sizeof(struct vring_used_elem) * num;
}
```

* 回到vring_create_virtqueue，接下来会调用vring_alloc_queue
* vring_alloc_queue
    * 先不管vring_use_dma_api，看else里的
    * 简单说就是调用alloc_pages_exact分配vring size大小的连续内存的物理页
    * alloc_pages_exact是kernel的内存管理函数，返回的是page的virtual address
    * 下面通过virt_to_phys把gva转为gpa，保存在dma_handle中

``` c
static void *vring_alloc_queue(struct virtio_device *vdev, size_t size,
			      dma_addr_t *dma_handle, gfp_t flag)
{
	if (vring_use_dma_api(vdev)) {
		return dma_alloc_coherent(vdev->dev.parent, size,
					  dma_handle, flag);
	} else {
		void *queue = alloc_pages_exact(PAGE_ALIGN(size), flag);
		if (queue) {
			phys_addr_t phys_addr = virt_to_phys(queue);
			*dma_handle = (dma_addr_t)phys_addr;
		}
		return queue;
	}
}
```

* 回到vring_create_virtqueue，接下来会调用vring_init

* vring_init
    * 把刚申请的内存的虚拟地址记录到vring结构体中，按成员size分配空间
``` c
static inline void vring_init(struct vring *vr, unsigned int num, void *p,
			      unsigned long align)
{
	vr->num = num;
	vr->desc = p;
	vr->avail = p + num*sizeof(struct vring_desc);
	vr->used = (void *)(((unsigned long)&vr->avail->ring[num] + sizeof(__virtio16)
		+ align-1) & ~(align - 1));
}
```

* 回到vring_create_virtqueue，接下来会调用__vring_new_virtqueue

* __vring_new_virtqueue
    * 到这才申请vring_virtqueue结构体（关于vring_virtqueue与vring与virtqueue的关系，看vring_virtqueue的定义就知道了，是vring_virtqueue包含vring和virtqueue）
    * vring_virtqueue分配好内存后开始赋值，主要是vring、virtqueue、notify等
        * 上面就说了callback传递了那么多层到这里才真正赋值给vq.callback，name也是
    * 然后一个for循环赋值descriptor table中的表项的next，这里可以看出表项vring_desc的next指针其实保存的不是地址，而是每一个表项在table中的位置，也就是说在decsriptor table中，每一个descriptor项不是通过地址索引组成链表的，而是通过在table中的位置，其实很好理解，因为上面vinrg在分配物理页的时候是调用alloc_pages_exact连续分配的，不用担心像普通的链表一样内存不连续的问题
    * 然后返回的是virtqueue，而不是vring_virtqueue，是因为内核有个黑魔法container_of，可以通过结构体成员的地址来获得这个结构体地址

``` c
struct virtqueue *__vring_new_virtqueue(unsigned int index,
					struct vring vring,
					struct virtio_device *vdev,
					bool weak_barriers,
					bool (*notify)(struct virtqueue *),
					void (*callback)(struct virtqueue *),
					const char *name)
{
	unsigned int i;
	struct vring_virtqueue *vq;

	vq = kmalloc(sizeof(*vq) + vring.num * sizeof(struct vring_desc_state),
		     GFP_KERNEL);
	vq->vring = vring;
	vq->vq.callback = callback;
	vq->vq.vdev = vdev;
	vq->vq.name = name;
	vq->vq.num_free = vring.num;
	vq->vq.index = index;
	vq->we_own_ring = false;
	vq->queue_dma_addr = 0;
	vq->queue_size_in_bytes = 0;
	vq->notify = notify;
	vq->weak_barriers = weak_barriers;
	vq->broken = false;
	vq->last_used_idx = 0;
	vq->num_added = 0;
	list_add_tail(&vq->vq.list, &vdev->vqs);
#ifdef DEBUG
	vq->in_use = false;
	vq->last_add_time_valid = false;
#endif

	vq->indirect = virtio_has_feature(vdev, VIRTIO_RING_F_INDIRECT_DESC);
	vq->event = virtio_has_feature(vdev, VIRTIO_RING_F_EVENT_IDX);

	/* No callback?  Tell other side not to bother us. */
	if (!callback)
		vq->vring.avail->flags |= cpu_to_virtio16(vdev, VRING_AVAIL_F_NO_INTERRUPT);

	/* Put everything in free lists. */
	vq->free_head = 0;
	for (i = 0; i < vring.num-1; i++)
		vq->vring.desc[i].next = cpu_to_virtio16(vdev, i + 1);
	memset(vq->desc_state, 0, vring.num * sizeof(struct vring_desc_state));

	return &vq->vq;
}
```

* 回到vring_create_virtqueue，接下里就是简单的三行，to_vvq就是上面说的黑魔法container_of宏，直接通过virtqueue获取vring_virtqueue，这里把申请的vring的物理地址（gpa）保存在vring_virtqueue的queue_dma_addr中，在后端qemu可以获取到gpa进一步转为hva
``` c
	to_vvq(vq)->queue_dma_addr = dma_addr;
	to_vvq(vq)->queue_size_in_bytes = queue_size_in_bytes;
	to_vvq(vq)->we_own_ring = true;
```

* 回到setup_vq，创建完vring、virtqueue、vring_virtqueue后激活queue
    * 很简单，向config space打中断，写入的数据是queue_dma_addr，就是vring的起始物理地址右移VIRTIO_PCI_QUEUE_ADDR_SHIFT位，这里是右移12位，x86分页模式右侧的12位是页内偏移地址，右移12位可以得出物理页框的地址
    * 把页框的物理地址通过中断通知给后端，qemu里面就获取到了vring的gpa，后面就好办了
``` c
	iowrite32(virtqueue_get_desc_addr(vq) >> VIRTIO_PCI_QUEUE_ADDR_SHIFT,
		  vp_dev->ioaddr + VIRTIO_PCI_QUEUE_PFN);
```

* 然后是把这个queue的中断号也通知给后端
```c
		iowrite16(msix_vec, vp_dev->ioaddr + VIRTIO_MSI_QUEUE_VECTOR);
```

* 回到vp_setup_vq，没什么说的，再回到vp_try_to_find_vqs，如果不是共享中断的话，会为每一个vq分配一个中断向量
``` c
		/* allocate per-vq irq if available and necessary */
		snprintf(vp_dev->msix_names[msix_vec],
			 sizeof *vp_dev->msix_names,
			 "%s-%s",
			 dev_name(&vp_dev->vdev.dev), names[i]);
		err = request_irq(vp_dev->msix_entries[msix_vec].vector,
				  vring_interrupt, 0,
				  vp_dev->msix_names[msix_vec],
				  vqs[i]);

```
* 回到vp_find_vqs，运行结束，回到init_vq，到这里virtqueue初始化基本结束